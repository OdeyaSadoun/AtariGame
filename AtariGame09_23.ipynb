{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb56877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow==2.5.1 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (2.5.1)\n",
      "Requirement already satisfied: gym in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (0.23.0)\n",
      "Requirement already satisfied: keras-rl2 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (1.0.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (2.11.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.19.5)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (3.20.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.6.3)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (0.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.34.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\programdata\\anaconda\\lib\\site-packages (from tensorflow==2.5.1) (0.37.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (2.5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (0.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.5.1) (3.3.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\programdata\\anaconda\\lib\\site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: ale-py~=0.7.4 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from gym) (0.7.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from ale-py~=0.7.4->gym) (5.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda\\lib\\site-packages (from importlib-metadata>=4.10.0->gym) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (2.0.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (63.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (2.19.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (2.28.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (1.26.11)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.1) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\אודיה סעדון\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.1) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.5.1 gym keras-rl2 gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e07a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3c2870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('ALE/SpaceInvaders-v5', render_mode='human')\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbc3983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30f6cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# episodes = 5\n",
    "# for episode in range(1, episodes+1):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     score = 0\n",
    "    \n",
    "#     while not done:\n",
    "#         time.sleep(0.1)\n",
    "#         action = random.choice([0,1,2,3,4,5])\n",
    "#         n_state, reward, done, info = env.step(action)\n",
    "#         score+=reward\n",
    "#     print('Episode:{} score:{}'.format(episode, score))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86a13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058f12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', padding='same', input_shape=(3,height, width, channels)))\n",
    "    model.add(Convolution2D(64, (4,4), strides=(2,22), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(actions,activation='linear'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068633a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29667855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(height, width, channels, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac44b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 3, 53, 40, 32)     6176      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 27, 2, 64)      32832     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 27, 2, 64)      36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,517,734\n",
      "Trainable params: 5,517,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a66bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66dd1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e05d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6847d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1, value_min=.1, value_test=.2, nb_steps=10000)\n",
    "    memory = SequentialMemory(limit=1000, window_length=3)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  enable_dueling_network=True, dueling_type='avg',\n",
    "                  nb_actions=actions, nb_steps_warmup=10000)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e82cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd2f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\אודיה סעדון\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\אודיה סעדון\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  515/10000: episode: 1, duration: 48.469s, episode steps: 515, steps per second:  11, episode reward: 165.000, mean reward:  0.320 [ 0.000, 30.000], mean action: 2.452 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 1171/10000: episode: 2, duration: 47.626s, episode steps: 656, steps per second:  14, episode reward: 220.000, mean reward:  0.335 [ 0.000, 25.000], mean action: 2.363 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 1448/10000: episode: 3, duration: 19.646s, episode steps: 277, steps per second:  14, episode reward: 35.000, mean reward:  0.126 [ 0.000, 15.000], mean action: 2.350 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 1976/10000: episode: 4, duration: 36.625s, episode steps: 528, steps per second:  14, episode reward: 215.000, mean reward:  0.407 [ 0.000, 30.000], mean action: 2.360 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 2800/10000: episode: 5, duration: 56.460s, episode steps: 824, steps per second:  15, episode reward: 325.000, mean reward:  0.394 [ 0.000, 30.000], mean action: 2.462 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 3104/10000: episode: 6, duration: 20.957s, episode steps: 304, steps per second:  15, episode reward: 100.000, mean reward:  0.329 [ 0.000, 25.000], mean action: 2.510 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 3799/10000: episode: 7, duration: 49.510s, episode steps: 695, steps per second:  14, episode reward: 205.000, mean reward:  0.295 [ 0.000, 25.000], mean action: 2.341 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 4359/10000: episode: 8, duration: 38.864s, episode steps: 560, steps per second:  14, episode reward: 160.000, mean reward:  0.286 [ 0.000, 25.000], mean action: 2.359 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 4842/10000: episode: 9, duration: 33.206s, episode steps: 483, steps per second:  15, episode reward: 170.000, mean reward:  0.352 [ 0.000, 30.000], mean action: 2.373 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 5452/10000: episode: 10, duration: 42.085s, episode steps: 610, steps per second:  14, episode reward: 260.000, mean reward:  0.426 [ 0.000, 30.000], mean action: 2.293 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 5839/10000: episode: 11, duration: 26.499s, episode steps: 387, steps per second:  15, episode reward: 70.000, mean reward:  0.181 [ 0.000, 30.000], mean action: 2.295 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 6352/10000: episode: 12, duration: 36.289s, episode steps: 513, steps per second:  14, episode reward: 155.000, mean reward:  0.302 [ 0.000, 30.000], mean action: 2.185 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 6881/10000: episode: 13, duration: 53.357s, episode steps: 529, steps per second:  10, episode reward: 95.000, mean reward:  0.180 [ 0.000, 25.000], mean action: 2.197 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 7177/10000: episode: 14, duration: 29.557s, episode steps: 296, steps per second:  10, episode reward: 80.000, mean reward:  0.270 [ 0.000, 20.000], mean action: 2.247 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 7666/10000: episode: 15, duration: 47.667s, episode steps: 489, steps per second:  10, episode reward: 140.000, mean reward:  0.286 [ 0.000, 30.000], mean action: 2.145 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 8470/10000: episode: 16, duration: 79.133s, episode steps: 804, steps per second:  10, episode reward: 155.000, mean reward:  0.193 [ 0.000, 30.000], mean action: 2.139 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 9180/10000: episode: 17, duration: 65.206s, episode steps: 710, steps per second:  11, episode reward: 140.000, mean reward:  0.197 [ 0.000, 30.000], mean action: 2.094 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      " 9686/10000: episode: 18, duration: 48.577s, episode steps: 506, steps per second:  10, episode reward: 125.000, mean reward:  0.247 [ 0.000, 30.000], mean action: 2.071 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
      "done, took 809.620 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1874527ad30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-4) )\n",
    "dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d71475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "render(mode='human') is deprecated. Please supply `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). The new `render_mode` keyword argument supports DPI scaling, audio, and native framerates.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30208\\3415142792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'episode_reward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\core.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\callbacks.py\u001b[0m in \u001b[0;36mon_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'on_action_end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\callbacks.py\u001b[0m in \u001b[0;36mon_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;34m\"\"\" Render environment at the end of each action \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\atari\\environment.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"human\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m             raise error.Error(\n\u001b[0m\u001b[0;32m    284\u001b[0m                 (\n\u001b[0;32m    285\u001b[0m                     \u001b[1;34m\"render(mode='human') is deprecated. Please supply `render_mode` when \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: render(mode='human') is deprecated. Please supply `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). The new `render_mode` keyword argument supports DPI scaling, audio, and native framerates."
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('SaveWeights/10k-Fast/dqn_weights.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c37e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('SaveWeights/10k-Fast/dqn_weights.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336fd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
